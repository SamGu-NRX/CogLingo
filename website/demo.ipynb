{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variable to handle OpenMP conflict, deleting this will take down prod\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "\n",
    "\n",
    "# Function definitions for each step (placeholders)\n",
    "def preprocess_audio(audio):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio, sr=None)\n",
    "    # Noise reduction\n",
    "    reduced_noise = nr.reduce_noise(y=y, sr=sr)\n",
    "    # Normalization\n",
    "    normalized_audio = librosa.util.normalize(reduced_noise)\n",
    "    return normalized_audio, sr\n",
    "\n",
    "def segment_speech(audio):\n",
    "    # Implement speech segmentation\n",
    "    segmented_speech = audio  # Placeholder for actual segmentation\n",
    "    return segmented_speech\n",
    "\n",
    "def transcribe_speech(audio, sr):\n",
    "    # Implement speech transcription using an ASR system\n",
    "    transcription = \"This is a sample transcription.\"  # Placeholder for actual transcription\n",
    "    return transcription\n",
    "\n",
    "def phoneme_analysis(transcription, standard_text):\n",
    "    # Implement phoneme analysis\n",
    "    phoneme_comparison = \"Phoneme comparison results\"  # Placeholder for actual analysis\n",
    "    return phoneme_comparison\n",
    "\n",
    "def calculate_pronunciation_score(phoneme_comparison):\n",
    "    # Calculate pronunciation score based on phoneme comparison\n",
    "    score = 85  # Placeholder\n",
    "    return score\n",
    "\n",
    "def generate_feedback(score):\n",
    "    # Generate visual feedback and improvement tips based on the score\n",
    "    feedback = \"Your pronunciation score is 85. Try to improve on specific phonemes.\"  # Placeholder for actual feedback\n",
    "    return feedback\n",
    "\n",
    "def mispronunciation_detection(audio, standard_text):\n",
    "    preprocessed_audio, sr = preprocess_audio(audio)\n",
    "    segmented_speech = segment_speech(preprocessed_audio)\n",
    "    transcription = transcribe_speech(segmented_speech, sr)\n",
    "    phoneme_comparison = phoneme_analysis(transcription, standard_text)\n",
    "    score = calculate_pronunciation_score(phoneme_comparison)\n",
    "    feedback = generate_feedback(score)\n",
    "    return transcription, score, feedback\n",
    "\n",
    "# Load the flowchart image\n",
    "flowchart_image_path = \"./public/image.png\"\n",
    "if os.path.exists(flowchart_image_path):\n",
    "    flowchart_image = Image.open(flowchart_image_path)\n",
    "else:\n",
    "    flowchart_image = None\n",
    "\n",
    "# Define the Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"<h1>Mispronunciation Detection and Correction System</h1>\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        if flowchart_image:\n",
    "            gr.Image(flowchart_image, label=\"Flowchart\")\n",
    "        else:\n",
    "            gr.Markdown(\"Flowchart image not found.\")\n",
    "        \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            audio_input = gr.Audio(type=\"numpy\", label=\"Record Your Speech\")\n",
    "            standard_text_input = gr.Textbox(label=\"Standard Text\")\n",
    "            submit_button = gr.Button(\"Submit\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            transcription_output = gr.Textbox(label=\"Transcription\")\n",
    "            score_output = gr.Number(label=\"Pronunciation Score\")\n",
    "            feedback_output = gr.Textbox(label=\"Feedback\")\n",
    "\n",
    "    submit_button.click(mispronunciation_detection, \n",
    "                        inputs=[audio_input, standard_text_input], \n",
    "                        outputs=[transcription_output, score_output, feedback_output])\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
